---
layout: post
title:  "生成式模型的前世今生（二）源起-生成式模型的定义"
date:   2021-07-07 19:27:58
categories: Notes
---
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>
[上一篇] [序言](gen1.html)

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>
如果直接在网上搜索一下「生成模型」，你会找到它的定义：
</font>   

><font size=3>在概率统计理论中，生成模型是指能够随机生成观测数据的模型，尤其是在给定某些隐含参数的条件下。它给观测值和标注数据序列指定一个联合概率分布。在机器学习中，生成模型可以用来直接对数据建模（例如根据某个变量的概率密度函数进行数据采样），也可以用来建立变量间的条件概率分布。条件概率分布可以由生成模型根据贝叶斯定理形成。(来源：维基百科）</font>

<font size=3>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;你很可能会看得头晕眼花，因为这是一个从数学的角度描述的很理论的概念。虽然经过了漫长的岁月，生成模型的研究有了长足的进步，并以包装好的模型、网络等形式呈现在我们的面前，但这不能改变它仍是一个数学中的概念的事实，它并不是随着人工智能的发展而出现的，它一直在那里，只是近些年才得以广泛应用。因此，在本节中我将先从数学的角度来叙述生成式模型的定义。我会尽量形象、直白地描述，但如果你主要关注生成模型的应用，并不想对生成模型的定义和原理有特别清晰的了解，也完全可以跳过本节，这不会影响你阅读后续内容。
</font>  

### 一、从概率论与数理统计开始
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>考试的时候，概率论与数理统计往往是相对较为简单的一门学科。和复杂、晦涩的微积分和线性代数相比，概率论显得那么贴近生活——掷色子、玩小球，我们甚至可以自己做实验来验证一个理论。然而，如果选择继续读研，你就会发现事情开始诡异起来了。矩阵理论虽然计算复杂了点，至少我的目标明确，我知道我要求的是奇异值还是特征向量，背过定理剩下就是算数的事嘛。但随机过程是什么鬼？增加了一个维度世界都崩了好嘛！顾客到商店怎么就泊松过程了，这不应该看你经营情况吗！明天有没有雨求什么转移矩阵，问气象局不行吗！</font>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>当然重点不在这里。只是因为生成模型的概念要依赖于概率统计理论，所以不得不先说一下概率论与数理统计。能够查到的大部份资料基本都是直接从机器学习说起了，但我想先从概率统计的角度解释一下生成模型。与生成模型相对的是判别模型，它们的区别简而言之就是，一个求条件概率分布，一个求联合概率分布。</font>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>想象这样的两个事件:1. 明天有可能要下雨(记为</font>$X_1$<font size=3>)，也可能不下雨(记为</font>$X_2$<font size=3>)。2. 明天小明可能骑车去上班(记为</font>$Y_1$<font size=3>)，也可能会开车去上班(记为</font>$Y_2$<font size=3>)，没有第三种情况。很遗憾，明天我没时间盯着小明是怎么走的，但是我需要知道他开没开车，以便做一些不可告人的事情。所以，我准备根据明天的天气情况做出一个可能的推断。</font>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>抛开数学，我可能会想，等明天看一下天气，如果没下雨，小明应该会骑车，毕竟他家离公司就1公里多点，骑车节能环保，还不堵；如果下雨了，小明可能就会开车，下雨骑车不太方便。没错，这就是典型的「判别式模型思维」，因为我认为</font><font size=2>$P(Y=Y_1|X=X_1)<P(Y=Y_2|X=X_1)$</font><font size=3>以及</font><font size=2>$P(Y=Y_1|X=X_2)>P(Y=Y_2|X=X_2)$</font><font size=3>。这本身就是一种常见的思维方式，需要先给定一个条件，我才能得出结论，我没法自己直接想象出一个结果来。</font>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>但是我也可以用另一种方式来进行推断，也就是「生成式模型思维」。我会想，明天出现「天没有下雨，小明骑着车去了公司」和「外面下雨了，小明开着车去了公司」这两种场景看上去更加自然，可能性也更大。而明天出现「天没有下雨，小明开着车，1公里堵了半小时」和「小明骑着车在暴雨中狂奔，只为了按时赶到公司上班」这两种略微有些脑残的场景的可能性显然更低。这时，我心里想的是</font><font size=2>$P(X=X_1,Y=Y_1)<P(X=X_1,Y=Y_2)$</font><font size=3>以及</font><font size=2>$P(X=X_2,Y=Y_1)>P(X=X_2,Y=Y_2)$</font><font size=3>。这种方法不用给定条件，也不用等到明天，我可以直接把所有的结果想象出来。</font>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>当然，这里只是我一个简单的思考过程。严格来说，我不能只看各个概率的大小关系，因为想要被称为「模型」，我还必须要知道每个概率准确的值，这样才能给出严谨准确的结果。想要估计这些概率的值，则需要用到我的一些经验，例如小明家到公司有多远，要走的路堵不堵，小明是个什么性格等等。在「生成式模型思维」思维中，我甚至还要估计一下明天下雨和不下雨的概率有多少，才能算出这几个联合概率。现在，你就当我经过思考和计算，已经得到了每个概率的值。那么现在我已经构建了两个完整的「模型」。再来看一下那个让人头晕的定义：
</font>

>在概率统计理论中，生成模型是指能够随机生成观测数据的模型，尤其是在给定某些隐含参数的条件下。它给观测值和标注数据序列指定一个联合概率分布。  

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>在「生成式模型思维」中，我做到了随机生成观测数据：我现在就能直接幻想出任意一种明天的天气，不用等到明天观测，也不用别人告诉我。与此同时，「判别式模型思维」则需要一个外界输入，需要给定一个先决条件：你先告诉我明天是什么天气，或者等明天看一下是什么天气，然后我才能根据这个天气做出推测。「生成式模型思维」中，我还给这些场景指定了联合概率分布，有了四个场景的概率，便得到了一个离散联合概率分布；而这也包含了一些隐含参数，例如小明家到公司有多远等等，这些情况将会影响概率值，也会影响最终的判断。</font>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>那么现在，你可能稍微有一点理解生成模型了。在使用联合概率分布的时候，我的脑海中直接「生成」了明天可能出现的场景，而不是根据天气情况做一个「判断」。再读一遍定义，虽然还做不到完全理解，但至少不再像是读天书了。不过你可能仍然有疑问，因为这一节似乎只有几个概率和数学有关系，这个「模型」又是个什么定义呢？</font>

### 二、浅谈机器学习
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>
看到这里你可能想问，不是说从数学的角度来叙述生成式模型吗，为什么要说机器学习？那是因为我认为机器学习也算数学的一门学科。维基百科的定义中，机器学习被描述为是人工智能的一个分支，这种定义也得到了广大专业人士的认可，但我却并不认同。早在1936年，Fisher就提出了线性判别分析（linear discriminant analysis，LDA）算法的雏形，这已经标志着机器学习算法开始萌芽。而世界上的首台计算机直到1946年才出现，人工智能的概念直到50年代才被提出。诚然，让机器拥有智能的思想出现的非常非常早，人工智能的发展也让机器学习方法得以飞速进步，但我认为即使人工智能的概念不出现，机器学习算法也能出现并发展，只是可能不叫这个名字，也不会发展这么快而已。不过也许因为他们之间这种相辅相成的关系，导致了他们不可能单独地发展。如果机器学习先出现，它的发展最终必将导致人工智能的出现，这样它才有应用价值；如果人工智能先出现，它在发展过程中一定会发现少了机器学习算法是不行的，从而促进机器学习出现和发展。这看似偶然也许是必然，必然性本就需要在大量的偶然性中才能表现出来，也许他们的内部根据和本质决定了他们终将同时出现和发展。但在我的心中，机器学习仍是数学的一个分支，它研究的是一种统计学理论，能够从数据中自动地获得规律，而计算的过程并不一定要依赖于机器；而人工智能是计算机科学的一个分支，它研究的是让机器拥有类似人类的智能的方法，涵盖了软硬件、不同学科甚至不同领域；他们相互交融，彼此促进发展，才有了今天这气势恢宏的智能时代。
</font>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>
回到我们的模型。在上一节，我们最后提到了「模型」这个东西。这是一个非常抽象的概念，但我还是想尽可能简单地说明它：「模型」是用数学符号刻画的一种关系结构。例如，任何一个函数都是一个模型，它用数学表达构建了自变量和因变量之间的变换关系。这个概念和机器学习并没有关系，但我仍把它放在了这一小节，因为我知道我没法从纯理论的角度把它讲明白，而机器学习的出现让解释变得简单，因为它「具象化」了「模型」这个概念。
</font>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>
上文我提到过，机器学习能够从数据中自动地获得规律；这个规律就是我们要的模型。上一节中，我提到过我是如何根据天气判断小明的出行情况的。在我之前认识小明的时间里，我一直看到他上下班的情况、了解他的性格、知道他的家庭条件，大脑通过学习，总结的规律就是他下雨时开车，不下时骑车，这就是一个模型。对于人的大脑来说，学习的过程还在继续，因为世界在变化，小明有可能破产把汽车卖了，也可能摔断了腿没法去上班；可若我是台计算机，当前的学习可以就此停止，学习到的规律，也就是概率分布，可以被作为计算机文件保存下来，我们便习惯性地将这个文件称为「模型文件」。至于是如何学习得出的这个规律，则有之前提到的「判别」和「生成」两种模式。
</font>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>
现在，我们再看一眼机器学习中生成模型的定义：
</font>

>
在机器学习中，生成模型可以用来直接对数据建模（例如根据某个变量的概率密度函数进行数据采样），也可以用来建立变量间的条件概率分布。条件概率分布可以由生成模型根据贝叶斯定理形成。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>
这个定义现在看并不复杂，因为生成模型在学习的过程中，连联合概率分布都构建了，想求边缘概率分布并采样、求条件概率分布，可以说易如反掌，定义中甚至把怎么求条件概率分布都告诉你了。例如，我在幻想明天的天气和小明出行方式的时候，我也可以只单独幻想一下明天的天气情况。因为我通过学习知道了明天四种情况发生的概率，我就可以算一下「明天下雨小明骑车去上班」和「明天下雨小明开车去上班」这两种情形发生的概率之和，与「明天不下雨小明骑车去上班」和「明天不下雨小明开车去上班」这两种情形发生的概率之和究竟哪个大，从而直接判断出明天下雨的概率大还是不下雨的概率大；而判别模型则没有这个能力。然而，这也带来了一个问题。因为我的目的是要知道小明明天是怎么走的，并不需要推断天气，因此在这个例子中，「生成式模型思维」其实引入了一些冗余的信息，这增加了学习的负担，并不利于构建一个有效的模型。不过，它也有着自己的优势，在后续的篇章中将慢慢浮现。
</font>

### 三、最终的目标
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>
不论判别模型还是生成模型，虽然学习规律的方式有所不同，最终的目标都是求条件概率。这就是为什么上一节我要专门说一下「模型」是用数学符号刻画的一种关系结构。既然是「关系」，那么至少要有两个主体才能建立，而这个「关系」存在的意义，就是当我给定其中一个主体时，能够利用模型来快速地推测出对应的另一个主体，不需要重复观测。当这个主体是概率论中的「事件」时，推测的过程显然就要用到条件概率。
</font>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>
也许你已经看了贝叶斯定理，明白了生成模型是怎么由联合概率求出条件概率的，但我仍想抛开数学，用我的例子再来解释一遍。「判别式模型思维」构建的本就是条件概率，因此当明天到来，就可以直接把观测到的明天的天气作为先决条件，直接就能得出小明骑车和开车的概率。而「生成式模型思维」中，当明天到来，我需要把实际观测到的的天气「放入」我的模型。例如明天下了雨，那么「下雨」这个事件放入我的模型后，我只需要比较一下「明天下雨小明骑车去上班」和「明天下雨小明开车去上班」这两个场景发生的概率，就能得出小明骑车和开车的概率了。
</font>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>
现在再来看一下这个例子：
</font>

>判别式模型：要确定一个羊是山羊还是绵羊，用判别式模型的方法是从历史数据中学习到模型，然后通过提取这只羊的特征来预测出这只羊是山羊的概率，是绵羊的概率。  
>
生成式模型：是根据山羊的特征首先学习出一个山羊的模型，然后根据绵羊的特征学习出一个绵羊的模型，然后从这只羊中提取特征，放到山羊模型中看概率是多少，再放到绵羊模型中看概率是多少，哪个大就是哪个。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size=3>
这个例子来自于知乎用户@Microstrong，是在</font>[<font size=3>这篇文章</font>](https://zhuanlan.zhihu.com/p/74586507)<font size=3>中提到的。当年我还不太懂生成式模型，在看了这个例子之后，就彻底糊涂了。不过如果理解了生成式模型，这个例子倒也变得不那么难懂了。判别模型中，特征是羊的条件，我只能根据特征做判断；生成模型中，我能自己直接幻想出羊的特征。现在，我用我自己的方式又详细地解释了一遍生成式模型的含义，通篇基本没有用到数学公式和图表，希望这样能更通俗易懂地解释生成模型。如果你还是没有理解，我只能说声抱歉，希望以后有人能写出更加简洁易懂的解析吧。
</font>

[下一篇] 考古-深度学习之前的生成式模型
